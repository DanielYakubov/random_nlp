{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de42262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f4f4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     /Users/danielyakubov/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6d4a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    "labeled_names = []\n",
    "\n",
    "def name_feature_extraction(name):\n",
    "    return {'last_letter': name[-1], 'last_two_letters': name[-2:]}\n",
    "\n",
    "# build a list of names labeled by gender\n",
    "for m_name, f_name in zip(male_names, female_names):\n",
    "    labeled_names.append((m_name, 'M'))\n",
    "    labeled_names.append((f_name, 'F'))\n",
    "\n",
    "random.shuffle(labeled_names)\n",
    "\n",
    "#adding features\n",
    "labeled_names = [(name_feature_extraction(name), label) for name, label in labeled_names]\n",
    "\n",
    "# dividing into train, test\n",
    "tenth = len(labeled_names)//10\n",
    "train = labeled_names[:tenth*9]\n",
    "test = labeled_names[tenth*9:]\n",
    "\n",
    "# training naive bayes classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29f770fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo M\n",
      "Trinity F\n",
      "Morpheus M\n",
      "Daniel M\n",
      "Isabela F\n"
     ]
    }
   ],
   "source": [
    "# some small tests to see effects\n",
    "for name in ['Neo', 'Trinity', 'Morpheus', 'Daniel', 'Isabela']:\n",
    "    name_features = name_feature_extraction(name)\n",
    "    print(name, classifier.classify(name_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62a8f23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7828282828282829\n"
     ]
    }
   ],
   "source": [
    "# actual accuracy\n",
    "print(nltk.classify.accuracy(classifier, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea680370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        last_two_letters = 'na'                F : M      =     89.2 : 1.0\n",
      "        last_two_letters = 'la'                F : M      =     59.8 : 1.0\n",
      "        last_two_letters = 'us'                M : F      =     36.9 : 1.0\n",
      "        last_two_letters = 'ia'                F : M      =     35.4 : 1.0\n",
      "             last_letter = 'a'                 F : M      =     33.1 : 1.0\n",
      "        last_two_letters = 'ta'                F : M      =     32.8 : 1.0\n",
      "        last_two_letters = 'rt'                M : F      =     32.3 : 1.0\n",
      "        last_two_letters = 'ra'                F : M      =     25.9 : 1.0\n",
      "        last_two_letters = 'sa'                F : M      =     25.7 : 1.0\n",
      "             last_letter = 'k'                 M : F      =     18.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# most informative\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d8d4c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5886\n"
     ]
    }
   ],
   "source": [
    "print(len(labeled_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d35ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different task\n",
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "501ffc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e609fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BE\n",
      "VBD\n",
      "AT\n",
      "NN\n",
      "BEZ\n",
      "VBN\n"
     ]
    }
   ],
   "source": [
    "def pos_features(prev_word, word, suc_word):\n",
    "    return {'suf1': word[-1],\n",
    "           'suf2': word[-2:],\n",
    "           'pre1': word[0],\n",
    "           'pre2': word[:2],\n",
    "           'previous_word': prev_word,\n",
    "           'succeeding_word': suc_word}\n",
    "\n",
    "tagged_data = [(w.lower(), tag) for w, tag in brown.tagged_words(categories='news')]\n",
    "# first item built in\n",
    "tagged_features = [(pos_features('NA', tagged_data[0][0], tagged_data[1][0]), tagged_data[0][1])]\n",
    "\n",
    "for i, (word, tag) in enumerate(list(tagged_data)[1:-1]):\n",
    "    prev_word, _ = tagged_data[i-1]\n",
    "    suc_word, _ = tagged_data[i+1]\n",
    "    tagged_features.append((pos_features(prev_word, word, suc_word), tag))\n",
    "# last item\n",
    "tagged_features.append((pos_features(tagged_data[-2][0], tagged_data[-1][0], 'NA'), tagged_data[-1][1]))\n",
    "\n",
    "random.shuffle(tagged_features)\n",
    "\n",
    "tenth = len(tagged_features)//10\n",
    "test_set = tagged_features[:tenth]\n",
    "dev_set = tagged_features[tenth:tenth*2]\n",
    "train_set = tagged_features[tenth*2:]\n",
    "\n",
    "# training the classifier\n",
    "pos_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# sanity check\n",
    "QA = ['Becky', 'said', 'the', 'car', 'is', 'red']\n",
    "QA = [w.lower() for w in QA]\n",
    "\n",
    "QA_features = [pos_features('NA', QA[0], QA[1])]\n",
    "\n",
    "for i, word in enumerate(QA[1:-1]):\n",
    "    QA_features.append(pos_features(QA[i-1], word, QA[i+1]))\n",
    "QA_features.append(pos_features(QA[-2], QA[-1], 'NA'))\n",
    "\n",
    "for item in QA_features:\n",
    "    print(pos_classifier.classify(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3586b1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    suf1 = '.'                 . : NN     =   6304.0 : 1.0\n",
      "                    suf2 = 'he'               AT : NN     =   4946.1 : 1.0\n",
      "                    pre2 = 'an'               CC : IN     =   4215.1 : 1.0\n",
      "                    pre1 = 'c'               MD* : IN     =   2765.7 : 1.0\n",
      "                    suf2 = 'ho'              WPS : NN     =   2688.2 : 1.0\n",
      "                    pre1 = \"'\"                '' : NNS    =   2615.6 : 1.0\n",
      "                    suf2 = 'to'               TO : JJ     =   2007.1 : 1.0\n",
      "                    pre1 = 'l'               RBR : IN     =   1958.3 : 1.0\n",
      "                    suf1 = 'h'               ABX : NNS    =   1951.8 : 1.0\n",
      "                    pre2 = 'it'              PPS : NN     =   1779.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# most informative features\n",
    "pos_classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f8dae259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8189955246146196\n",
      "0.8203878667329687\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(nltk.classify.accuracy(pos_classifier, dev_set))\n",
    "print(nltk.classify.accuracy(pos_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf00f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
