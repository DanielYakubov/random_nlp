{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de42262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f4f4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     /Users/danielyakubov/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6d4a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    "labeled_names = []\n",
    "\n",
    "def name_feature_extraction(name):\n",
    "    return {'last_letter': name[-1], 'last_two_letters': name[-2:]}\n",
    "\n",
    "# build a list of names labeled by gender\n",
    "for m_name, f_name in zip(male_names, female_names):\n",
    "    labeled_names.append((m_name, 'M'))\n",
    "    labeled_names.append((f_name, 'F'))\n",
    "\n",
    "random.shuffle(labeled_names)\n",
    "\n",
    "#adding features\n",
    "labeled_names = [(name_feature_extraction(name), label) for name, label in labeled_names]\n",
    "\n",
    "# dividing into train, test\n",
    "tenth = len(labeled_names)//10\n",
    "train = labeled_names[:tenth*9]\n",
    "test = labeled_names[tenth*9:]\n",
    "\n",
    "# training naive bayes classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29f770fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo M\n",
      "Trinity F\n",
      "Morpheus M\n",
      "Daniel M\n",
      "Isabela F\n"
     ]
    }
   ],
   "source": [
    "# some small tests to see effects\n",
    "for name in ['Neo', 'Trinity', 'Morpheus', 'Daniel', 'Isabela']:\n",
    "    name_features = name_feature_extraction(name)\n",
    "    print(name, classifier.classify(name_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62a8f23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7828282828282829\n"
     ]
    }
   ],
   "source": [
    "# actual accuracy\n",
    "print(nltk.classify.accuracy(classifier, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea680370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        last_two_letters = 'na'                F : M      =     89.2 : 1.0\n",
      "        last_two_letters = 'la'                F : M      =     59.8 : 1.0\n",
      "        last_two_letters = 'us'                M : F      =     36.9 : 1.0\n",
      "        last_two_letters = 'ia'                F : M      =     35.4 : 1.0\n",
      "             last_letter = 'a'                 F : M      =     33.1 : 1.0\n",
      "        last_two_letters = 'ta'                F : M      =     32.8 : 1.0\n",
      "        last_two_letters = 'rt'                M : F      =     32.3 : 1.0\n",
      "        last_two_letters = 'ra'                F : M      =     25.9 : 1.0\n",
      "        last_two_letters = 'sa'                F : M      =     25.7 : 1.0\n",
      "             last_letter = 'k'                 M : F      =     18.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# most informative\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d8d4c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5886\n"
     ]
    }
   ],
   "source": [
    "print(len(labeled_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d35ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different task\n",
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "501ffc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e609fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BE\n",
      "VBD\n",
      "AT\n",
      "NN\n",
      "BEZ\n",
      "VBN\n"
     ]
    }
   ],
   "source": [
    "def pos_features(prev_word, word, suc_word):\n",
    "    return {'suf1': word[-1],\n",
    "           'suf2': word[-2:],\n",
    "           'pre1': word[0],\n",
    "           'pre2': word[:2],\n",
    "           'previous_word': prev_word,\n",
    "           'succeeding_word': suc_word}\n",
    "\n",
    "tagged_data = [(w.lower(), tag) for w, tag in brown.tagged_words(categories='news')]\n",
    "# first item built in\n",
    "tagged_features = [(pos_features('NA', tagged_data[0][0], tagged_data[1][0]), tagged_data[0][1])]\n",
    "\n",
    "for i, (word, tag) in enumerate(list(tagged_data)[1:-1]):\n",
    "    prev_word, _ = tagged_data[i-1]\n",
    "    suc_word, _ = tagged_data[i+1]\n",
    "    tagged_features.append((pos_features(prev_word, word, suc_word), tag))\n",
    "# last item\n",
    "tagged_features.append((pos_features(tagged_data[-2][0], tagged_data[-1][0], 'NA'), tagged_data[-1][1]))\n",
    "\n",
    "random.shuffle(tagged_features)\n",
    "\n",
    "tenth = len(tagged_features)//10\n",
    "test_set = tagged_features[:tenth]\n",
    "dev_set = tagged_features[tenth:tenth*2]\n",
    "train_set = tagged_features[tenth*2:]\n",
    "\n",
    "# training the classifier\n",
    "pos_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# sanity check\n",
    "QA = ['Becky', 'said', 'the', 'car', 'is', 'red']\n",
    "QA = [w.lower() for w in QA]\n",
    "\n",
    "QA_features = [pos_features('NA', QA[0], QA[1])]\n",
    "\n",
    "for i, word in enumerate(QA[1:-1]):\n",
    "    QA_features.append(pos_features(QA[i-1], word, QA[i+1]))\n",
    "QA_features.append(pos_features(QA[-2], QA[-1], 'NA'))\n",
    "\n",
    "for item in QA_features:\n",
    "    print(pos_classifier.classify(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3586b1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    suf1 = '.'                 . : NN     =   6304.0 : 1.0\n",
      "                    suf2 = 'he'               AT : NN     =   4946.1 : 1.0\n",
      "                    pre2 = 'an'               CC : IN     =   4215.1 : 1.0\n",
      "                    pre1 = 'c'               MD* : IN     =   2765.7 : 1.0\n",
      "                    suf2 = 'ho'              WPS : NN     =   2688.2 : 1.0\n",
      "                    pre1 = \"'\"                '' : NNS    =   2615.6 : 1.0\n",
      "                    suf2 = 'to'               TO : JJ     =   2007.1 : 1.0\n",
      "                    pre1 = 'l'               RBR : IN     =   1958.3 : 1.0\n",
      "                    suf1 = 'h'               ABX : NNS    =   1951.8 : 1.0\n",
      "                    pre2 = 'it'              PPS : NN     =   1779.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# most informative features\n",
    "pos_classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f8dae259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8189955246146196\n",
      "0.8203878667329687\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(nltk.classify.accuracy(pos_classifier, dev_set))\n",
    "print(nltk.classify.accuracy(pos_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bf00f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to\n",
      "[nltk_data]     /Users/danielyakubov/nltk_data...\n",
      "[nltk_data]   Package udhr is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Sklearn\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# corpus\n",
    "import nltk\n",
    "from nltk.corpus import udhr\n",
    "nltk.download('udhr')\n",
    "\n",
    "import random\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1682945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abkhaz-Cyrillic+Abkh',\n",
       " 'Abkhaz-UTF8',\n",
       " 'Achehnese-Latin1',\n",
       " 'Achuar-Shiwiar-Latin1',\n",
       " 'Adja-UTF8',\n",
       " 'Afaan_Oromo_Oromiffa-Latin1',\n",
       " 'Afrikaans-Latin1',\n",
       " 'Aguaruna-Latin1',\n",
       " 'Akuapem_Twi-UTF8',\n",
       " 'Albanian_Shqip-Latin1',\n",
       " 'Amahuaca',\n",
       " 'Amahuaca-Latin1',\n",
       " 'Amarakaeri-Latin1',\n",
       " 'Amuesha-Yanesha-UTF8',\n",
       " 'Arabela-Latin1',\n",
       " 'Arabic_Alarabia-Arabic',\n",
       " 'Asante-UTF8',\n",
       " 'Ashaninca-Latin1',\n",
       " 'Asheninca-Latin1',\n",
       " 'Asturian_Bable-Latin1',\n",
       " 'Aymara-Latin1',\n",
       " 'Balinese-Latin1',\n",
       " 'Bambara-UTF8',\n",
       " 'Baoule-UTF8',\n",
       " 'Basque_Euskara-Latin1',\n",
       " 'Batonu_Bariba-UTF8',\n",
       " 'Belorus_Belaruski-Cyrillic',\n",
       " 'Belorus_Belaruski-UTF8',\n",
       " 'Bemba-Latin1',\n",
       " 'Bengali-UTF8',\n",
       " 'Beti-UTF8',\n",
       " 'Bichelamar-Latin1',\n",
       " 'Bikol_Bicolano-Latin1',\n",
       " 'Bora-Latin1',\n",
       " 'Bosnian_Bosanski-Cyrillic',\n",
       " 'Bosnian_Bosanski-Latin2',\n",
       " 'Bosnian_Bosanski-UTF8',\n",
       " 'Breton-Latin1',\n",
       " 'Bugisnese-Latin1',\n",
       " 'Bulgarian_Balgarski-Cyrillic',\n",
       " 'Bulgarian_Balgarski-UTF8',\n",
       " 'Cakchiquel-Latin1',\n",
       " 'Campa_Pajonalino-Latin1',\n",
       " 'Candoshi-Shapra-Latin1',\n",
       " 'Caquinte-Latin1',\n",
       " 'Cashibo-Cacataibo-Latin1',\n",
       " 'Cashinahua-Latin1',\n",
       " 'Catalan-Latin1',\n",
       " 'Catalan_Catala-Latin1',\n",
       " 'Cebuano-Latin1',\n",
       " 'Chamorro-Latin1',\n",
       " 'Chayahuita-Latin1',\n",
       " 'Chechewa_Nyanja-Latin1',\n",
       " 'Chickasaw-Latin1',\n",
       " 'Chinanteco-Ajitlan-Latin1',\n",
       " 'Chinanteco-UTF8',\n",
       " 'Chinese_Mandarin-GB2312',\n",
       " 'Chuuk_Trukese-Latin1',\n",
       " 'Cokwe-Latin1',\n",
       " 'Corsican-Latin1',\n",
       " 'Croatian_Hrvatski-Latin2',\n",
       " 'Czech-Latin2',\n",
       " 'Czech-UTF8',\n",
       " 'Czech_Cesky-Latin2',\n",
       " 'Czech_Cesky-UTF8',\n",
       " 'Dagaare-UTF8',\n",
       " 'Dagbani-UTF8',\n",
       " 'Dangme-UTF8',\n",
       " 'Danish_Dansk-Latin1',\n",
       " 'Dendi-UTF8',\n",
       " 'Ditammari-UTF8',\n",
       " 'Dutch_Nederlands-Latin1',\n",
       " 'Edo-Latin1',\n",
       " 'English-Latin1',\n",
       " 'Esperanto-UTF8',\n",
       " 'Estonian_Eesti-Latin1',\n",
       " 'Ewe_Eve-UTF8',\n",
       " 'Fante-UTF8',\n",
       " 'Faroese-Latin1',\n",
       " 'Farsi_Persian-UTF8',\n",
       " 'Farsi_Persian-v2-UTF8',\n",
       " 'Fijian-Latin1',\n",
       " 'Filipino_Tagalog-Latin1',\n",
       " 'Finnish_Suomi-Latin1',\n",
       " 'Fon-UTF8',\n",
       " 'French_Francais-Latin1',\n",
       " 'Frisian-Latin1',\n",
       " 'Friulian_Friulano-Latin1',\n",
       " 'Ga-UTF8',\n",
       " 'Gagauz_Gagauzi-UTF8',\n",
       " 'Galician_Galego-Latin1',\n",
       " 'Garifuna_Garifuna-Latin1',\n",
       " 'German_Deutsch-Latin1',\n",
       " 'Gonja-UTF8',\n",
       " 'Greek_Ellinika-Greek',\n",
       " 'Greek_Ellinika-UTF8',\n",
       " 'Greenlandic_Inuktikut-Latin1',\n",
       " 'Guarani-Latin1',\n",
       " 'Guen_Mina-UTF8',\n",
       " 'HaitianCreole_Kreyol-Latin1',\n",
       " 'HaitianCreole_Popular-Latin1',\n",
       " 'Hani-Latin1',\n",
       " 'Hausa_Haoussa-Latin1',\n",
       " 'Hawaiian-UTF8',\n",
       " 'Hebrew_Ivrit-Hebrew',\n",
       " 'Hebrew_Ivrit-UTF8',\n",
       " 'Hiligaynon-Latin1',\n",
       " 'Hindi-UTF8',\n",
       " 'Hindi_web-UTF8',\n",
       " 'Hmong_Miao-Sichuan-Guizhou-Yunnan-Latin1',\n",
       " 'Hmong_Miao-SouthernEast-Guizhou-Latin1',\n",
       " 'Hmong_Miao_Northern-East-Guizhou-Latin1',\n",
       " 'Hrvatski_Croatian-Latin2',\n",
       " 'Huasteco-Latin1',\n",
       " 'Huitoto_Murui-Latin1',\n",
       " 'Hungarian_Magyar-Latin1',\n",
       " 'Hungarian_Magyar-Latin2',\n",
       " 'Hungarian_Magyar-UTF8',\n",
       " 'Ibibio_Efik-Latin1',\n",
       " 'Icelandic_Yslenska-Latin1',\n",
       " 'Ido-Latin1',\n",
       " 'Igbo-UTF8',\n",
       " 'Iloko_Ilocano-Latin1',\n",
       " 'Indonesian-Latin1',\n",
       " 'Interlingua-Latin1',\n",
       " 'Inuktikut_Greenlandic-Latin1',\n",
       " 'IrishGaelic_Gaeilge-Latin1',\n",
       " 'Italian-Latin1',\n",
       " 'Italian_Italiano-Latin1',\n",
       " 'Japanese_Nihongo-EUC',\n",
       " 'Japanese_Nihongo-SJIS',\n",
       " 'Japanese_Nihongo-UTF8',\n",
       " 'Javanese-Latin1',\n",
       " 'Jola-Fogny_Diola-UTF8',\n",
       " 'Kabye-UTF8',\n",
       " 'Kannada-UTF8',\n",
       " 'Kaonde-Latin1',\n",
       " 'Kapampangan-Latin1',\n",
       " 'Kasem-UTF8',\n",
       " 'Kazakh-Cyrillic',\n",
       " 'Kazakh-UTF8',\n",
       " 'Kiche_Quiche-Latin1',\n",
       " 'Kicongo-Latin1',\n",
       " 'Kimbundu_Mbundu-Latin1',\n",
       " 'Kinyamwezi_Nyamwezi-Latin1',\n",
       " 'Kinyarwanda-Latin1',\n",
       " 'Kituba-Latin1',\n",
       " 'Korean_Hankuko-UTF8',\n",
       " 'Kpelewo-UTF8',\n",
       " 'Krio-UTF8',\n",
       " 'Kurdish-UTF8',\n",
       " 'Lamnso_Lam-nso-UTF8',\n",
       " 'Latin_Latina-Latin1',\n",
       " 'Latin_Latina-v2-Latin1',\n",
       " 'Latvian-Latin1',\n",
       " 'Limba-UTF8',\n",
       " 'Lingala-Latin1',\n",
       " 'Lithuanian_Lietuviskai-Baltic',\n",
       " 'Lozi-Latin1',\n",
       " 'Luba-Kasai_Tshiluba-Latin1',\n",
       " 'Luganda_Ganda-Latin1',\n",
       " 'Lunda_Chokwe-lunda-Latin1',\n",
       " 'Luvale-Latin1',\n",
       " 'Luxembourgish_Letzebuergeusch-Latin1',\n",
       " 'Macedonian-UTF8',\n",
       " 'Madurese-Latin1',\n",
       " 'Makonde-Latin1',\n",
       " 'Malagasy-Latin1',\n",
       " 'Malay_BahasaMelayu-Latin1',\n",
       " 'Maltese-UTF8',\n",
       " 'Mam-Latin1',\n",
       " 'Maninka-UTF8',\n",
       " 'Maori-Latin1',\n",
       " 'Mapudungun_Mapuzgun-Latin1',\n",
       " 'Mapudungun_Mapuzgun-UTF8',\n",
       " 'Marshallese-Latin1',\n",
       " 'Matses-Latin1',\n",
       " 'Mayan_Yucateco-Latin1',\n",
       " 'Mazahua_Jnatrjo-UTF8',\n",
       " 'Mazateco-Latin1',\n",
       " 'Mende-UTF8',\n",
       " 'Mikmaq_Micmac-Mikmaq-Latin1',\n",
       " 'Minangkabau-Latin1',\n",
       " 'Miskito_Miskito-Latin1',\n",
       " 'Mixteco-Latin1',\n",
       " 'Mongolian_Khalkha-Cyrillic',\n",
       " 'Mongolian_Khalkha-UTF8',\n",
       " 'Moore_More-UTF8',\n",
       " 'Nahuatl-Latin1',\n",
       " 'Ndebele-Latin1',\n",
       " 'Nepali-UTF8',\n",
       " 'Ngangela_Nyemba-Latin1',\n",
       " 'NigerianPidginEnglish-Latin1',\n",
       " 'Nomatsiguenga-Latin1',\n",
       " 'NorthernSotho_Pedi-Sepedi-Latin1',\n",
       " 'Norwegian-Latin1',\n",
       " 'Norwegian_Norsk-Bokmal-Latin1',\n",
       " 'Norwegian_Norsk-Nynorsk-Latin1',\n",
       " 'Nyanja_Chechewa-Latin1',\n",
       " 'Nyanja_Chinyanja-Latin1',\n",
       " 'Nzema-UTF8',\n",
       " 'OccitanAuvergnat-Latin1',\n",
       " 'OccitanLanguedocien-Latin1',\n",
       " 'Oromiffa_AfaanOromo-Latin1',\n",
       " 'Osetin_Ossetian-UTF8',\n",
       " 'Oshiwambo_Ndonga-Latin1',\n",
       " 'Otomi_Nahnu-Latin1',\n",
       " 'Paez-Latin1',\n",
       " 'Palauan-Latin1',\n",
       " 'Peuhl-UTF8',\n",
       " 'Picard-Latin1',\n",
       " 'Pipil-Latin1',\n",
       " 'Polish-Latin2',\n",
       " 'Polish_Polski-Latin2',\n",
       " 'Ponapean-Latin1',\n",
       " 'Portuguese_Portugues-Latin1',\n",
       " 'Pulaar-UTF8',\n",
       " 'Punjabi_Panjabi-UTF8',\n",
       " 'Purhepecha-UTF8',\n",
       " 'Qechi_Kekchi-Latin1',\n",
       " 'Quechua-Latin1',\n",
       " 'Quichua-Latin1',\n",
       " 'Rarotongan_MaoriCookIslands-Latin1',\n",
       " 'Rhaeto-Romance_Rumantsch-Latin1',\n",
       " 'Romani-Latin1',\n",
       " 'Romani-UTF8',\n",
       " 'Romanian-Latin2',\n",
       " 'Romanian_Romana-Latin2',\n",
       " 'Rukonzo_Konjo-Latin1',\n",
       " 'Rundi_Kirundi-Latin1',\n",
       " 'Runyankore-rukiga_Nkore-kiga-Latin1',\n",
       " 'Russian-Cyrillic',\n",
       " 'Russian-UTF8',\n",
       " 'Russian_Russky-Cyrillic',\n",
       " 'Russian_Russky-UTF8',\n",
       " 'Sami_Lappish-UTF8',\n",
       " 'Sammarinese-Latin1',\n",
       " 'Samoan-Latin1',\n",
       " 'Sango_Sangho-Latin1',\n",
       " 'Sanskrit-UTF8',\n",
       " 'Saraiki-UTF8',\n",
       " 'Sardinian-Latin1',\n",
       " 'ScottishGaelic_GaidhligAlbanach-Latin1',\n",
       " 'Seereer-UTF8',\n",
       " 'Serbian_Srpski-Cyrillic',\n",
       " 'Serbian_Srpski-Latin2',\n",
       " 'Serbian_Srpski-UTF8',\n",
       " 'Sharanahua-Latin1',\n",
       " 'Shipibo-Conibo-Latin1',\n",
       " 'Shona-Latin1',\n",
       " 'Sinhala-UTF8',\n",
       " 'Siswati-Latin1',\n",
       " 'Slovak-Latin2',\n",
       " 'Slovak_Slovencina-Latin2',\n",
       " 'Slovenian_Slovenscina-Latin2',\n",
       " 'SolomonsPidgin_Pijin-Latin1',\n",
       " 'Somali-Latin1',\n",
       " 'Soninke_Soninkanxaane-UTF8',\n",
       " 'Sorbian-Latin2',\n",
       " 'SouthernSotho_Sotho-Sesotho-Sutu-Sesutu-Latin1',\n",
       " 'Spanish-Latin1',\n",
       " 'Spanish_Espanol-Latin1',\n",
       " 'Sukuma-Latin1',\n",
       " 'Sundanese-Latin1',\n",
       " 'Sussu_Soussou-Sosso-Soso-Susu-UTF8',\n",
       " 'Swaheli-Latin1',\n",
       " 'Swahili_Kiswahili-Latin1',\n",
       " 'Swedish_Svenska-Latin1',\n",
       " 'Tahitian-UTF8',\n",
       " 'Tenek_Huasteco-Latin1',\n",
       " 'Tetum-Latin1',\n",
       " 'Themne_Temne-UTF8',\n",
       " 'Tiv-Latin1',\n",
       " 'Toba-UTF8',\n",
       " 'Tojol-abal-Latin1',\n",
       " 'TokPisin-Latin1',\n",
       " 'Tonga-Latin1',\n",
       " 'Tongan_Tonga-Latin1',\n",
       " 'Totonaco-Latin1',\n",
       " 'Trukese_Chuuk-Latin1',\n",
       " 'Turkish_Turkce-Turkish',\n",
       " 'Turkish_Turkce-UTF8',\n",
       " 'Tzeltal-Latin1',\n",
       " 'Tzotzil-Latin1',\n",
       " 'Uighur_Uyghur-Latin1',\n",
       " 'Uighur_Uyghur-UTF8',\n",
       " 'Ukrainian-Cyrillic',\n",
       " 'Ukrainian-UTF8',\n",
       " 'Umbundu-Latin1',\n",
       " 'Urarina-Latin1',\n",
       " 'Uzbek-Latin1',\n",
       " 'Vietnamese-ALRN-UTF8',\n",
       " 'Vietnamese-UTF8',\n",
       " 'Vlach-Latin1',\n",
       " 'Walloon_Wallon-Latin1',\n",
       " 'Wama-UTF8',\n",
       " 'Waray-Latin1',\n",
       " 'Wayuu-Latin1',\n",
       " 'Welsh_Cymraeg-Latin1',\n",
       " 'WesternSotho_Tswana-Setswana-Latin1',\n",
       " 'Wolof-Latin1',\n",
       " 'Xhosa-Latin1',\n",
       " 'Yagua-Latin1',\n",
       " 'Yao-Latin1',\n",
       " 'Yapese-Latin1',\n",
       " 'Yoruba-UTF8',\n",
       " 'Zapoteco-Latin1',\n",
       " 'Zapoteco-SanLucasQuiavini-Latin1',\n",
       " 'Zhuang-Latin1',\n",
       " 'Zulu-Latin1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do we have available here?\n",
    "udhr.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00aa1187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parents', 'have', 'a', 'prior', 'right', 'to', 'choose', 'the', 'kind', 'of', 'education', 'that', 'shall', 'be', 'given', 'to', 'their', 'children', '.'] English\n"
     ]
    }
   ],
   "source": [
    "# the data\n",
    "eng = udhr.sents(fileids='English-Latin1')\n",
    "ger = udhr.sents(fileids='German_Deutsch-Latin1')\n",
    "data = [(sent , 'English') for sent in eng] + [(sent, 'German') for sent in ger]\n",
    "random.shuffle(data)\n",
    "X, Y = zip(*data)\n",
    "print(X[0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1356d764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ü', 'ä', '(', ')', 'ö', 'ß'}\n",
      "{'q'}\n"
     ]
    }
   ],
   "source": [
    "ger_chars = set(''.join([''.join(s).lower() for s in ger]))\n",
    "eng_chars = set(''.join([''.join(s).lower() for s in eng]))\n",
    "\n",
    "ger_only_chars = ger_chars - eng_chars # want to find out some obvious giveaways that a text is german\n",
    "print(ger_only_chars)\n",
    "eng_only_chars = eng_chars - ger_chars # the letter 'q' apparently\n",
    "print(eng_only_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61ef28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_only_chars = ['ü', 'ä', 'ö', 'ß'] # manually removed symbols\n",
    "eng_only_chars = ['q']\n",
    "chars_to_check = ger_only_chars + eng_only_chars\n",
    "\n",
    "def feature_extraction_ge(sent_toks):\n",
    "    \"\"\"takes a list and returns a dict of features\n",
    "    the features I care about for this are \n",
    "    1) has certain characters (obvious giveaway)\n",
    "    2) how many words are title cased, German title cases all nouns\n",
    "    3) Average word length \"\"\"\n",
    "    C = Counter()\n",
    "    \n",
    "    # we don't really need counts of these, 0,1 work fine, so using a set is okay\n",
    "    chars_in_sent = set(''.join(sent_toks).lower())\n",
    "    for char in chars_to_check:\n",
    "        if char in chars_in_sent:\n",
    "            C[f'has_let_{char}'] += 1\n",
    "        else:\n",
    "            C[f'has_let_{char}'] = 0\n",
    "    \n",
    "    for tok in sent_toks:\n",
    "        if tok.istitle():\n",
    "            C['title_case_cnt'] += 1\n",
    "            \n",
    "    avg_word_len = sum([len(tok) for tok in sent_toks])/len(sent_toks)\n",
    "    C[\"avg_word_length\"] += avg_word_len\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03faa6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to convert our X to features\n",
    "X_features = [feature_extraction_ge(sent) for sent in X]\n",
    "\n",
    "#dict vectorize\n",
    "vectorizer = feature_extraction.DictVectorizer(sparse=False)\n",
    "vect_X = vectorizer.fit_transform(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3b721534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9230769230769231\n",
      "[[ 9  0]\n",
      " [ 2 15]]\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(vect_X, Y, test_size=0.2)\n",
    "# classifier\n",
    "classifier = naive_bayes.MultinomialNB(alpha=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "320b12c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8. 0. 0. 0. 0. 0. 2.]\n",
      "            pred = English\n",
      "            gold = German\n",
      "[6.28571429 0.         0.         0.         0.         0.\n",
      " 4.        ]\n",
      "            pred = English\n",
      "            gold = German\n"
     ]
    }
   ],
   "source": [
    "# what was the mistake in classification?\n",
    "for x, pred, gold in zip(X_test, y_pred, y_test):\n",
    "    if pred != gold:\n",
    "        print(f\"\"\"{x}\n",
    "            pred = {pred}\n",
    "            gold = {gold}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "465269ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text = Hello my name is daniel how do you feel today? I feel fine its actually awesome\n",
      "    gold = English\n",
      "    pred = English\n",
      "text = There is nothing in the world so irresistibly contagious as laughter and good humor.\n",
      "    gold = English\n",
      "    pred = English\n",
      "text = Der Ball ist rund. Das Spiel dauert 90 Minuten\n",
      "    gold = German\n",
      "    pred = German\n",
      "text = Shall I compare thee to a summer's day?\n",
      "    gold = English\n",
      "    pred = English\n",
      "text = Alles hat ein Ende, nur die Wurst hat zwei\n",
      "    gold = German\n",
      "    pred = English\n",
      "text = Übung macht den Meister\n",
      "    gold = German\n",
      "    pred = German\n",
      "text = Sweet are the uses of adversity which, like the toad, ugly and venomous, wears yet a precious jewel in his head.\n",
      "    gold = English\n",
      "    pred = English\n"
     ]
    }
   ],
   "source": [
    "fun_text = ['Hello my name is daniel how do you feel today? I feel fine its actually awesome',\n",
    "           'There is nothing in the world so irresistibly contagious as laughter and good humor.',\n",
    "           'Der Ball ist rund. Das Spiel dauert 90 Minuten',\n",
    "            'Shall I compare thee to a summer\\'s day?',\n",
    "           'Alles hat ein Ende, nur die Wurst hat zwei',\n",
    "           'Übung macht den Meister',\n",
    "           'Sweet are the uses of adversity which, like the toad, ugly and venomous, wears yet a precious jewel in his head.']\n",
    "\n",
    "gold_y = ['English', 'English', 'German', 'English', 'German', 'German', 'English']\n",
    "split_text = [s.split() for s in fun_text]\n",
    "features = [feature_extraction_ge(s) for s in split_text]\n",
    "fun_vects = vectorizer.fit_transform(features)\n",
    "pred_y = classifier.predict(fun_vects)\n",
    "\n",
    "for t, g, p in zip(fun_text, gold_y, pred_y):\n",
    "    print(f\"\"\"text = {t}\n",
    "    gold = {g}\n",
    "    pred = {p}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b302dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e09fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
